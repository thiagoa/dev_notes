## 2019-04-12 - PostgreSQL

### Fast counting solution with a cache table

Comes at the expense of slower updates. Let's hand-craft a counter
cache for storing the count of orders per client:


```sql
DROP TABLE IF EXISTS orders;
DROP TABLE IF EXISTS orders_count;
CREATE TABLE orders(id serial not null, client_id bigint);
INSERT INTO orders(client_id) VALUES(1), (2), (1);

START TRANSACTION;

CREATE TABLE orders_count(client_id bigint, c bigint, UNIQUE(client_id));

CREATE OR REPLACE FUNCTION orders_count() RETURNS trigger LANGUAGE plpgsql AS $$
DECLARE
  row RECORD;
BEGIN
  IF TG_OP = 'INSERT' THEN
    INSERT INTO orders_count(client_id, c) VALUES(NEW.client_id, 1)
      ON CONFLICT(client_id) DO
      UPDATE SET c = orders_count.c + 1;
    RETURN NEW;
  ELSIF TG_OP = 'DELETE' THEN
    UPDATE orders_count SET c = c - 1 WHERE client_id = OLD.client_id;
    RETURN OLD;
  ELSE
    DELETE FROM orders_count;
    RETURN NULL;
  END IF;
END;
$$;

CREATE TRIGGER orders_count_mod AFTER INSERT OR DELETE ON orders
   FOR EACH ROW EXECUTE PROCEDURE orders_count();

CREATE TRIGGER orders_count_trunc AFTER TRUNCATE ON orders
   FOR EACH STATEMENT EXECUTE PROCEDURE orders_count();

INSERT INTO orders_count(client_id, c)
  SELECT client_id, COUNT(*) FROM orders GROUP BY client_id;

COMMIT;
```

Since we've pre-populated the table, initially we'll get the following
results:

```sql
SELECT * FROM orders_count;
```

```
 client_id | c
-----------+---
         2 | 1
         1 | 2
(2 rows)
```

Let's insert another entry for client 1:

```sql
INSERT INTO orders(client_id) VALUES(1);
```

Which updates the count for client 1:

```
 client_id | c
-----------+---
         2 | 1
         1 | 3
(2 rows)
```

A new order for client 40 will create a new row:

```sql
INSERT INTO orders(client_id) VALUES(40);
```

```
 client_id | c
-----------+---
         2 | 1
         1 | 3
        40 | 1
(3 rows)
```

Let's revert to the initial state by deleting the newly inserted
orders:

```sql
DELETE FROM orders WHERE client_id = 40;
DELETE FROM orders WHERE id IN (SELECT id FROM orders WHERE client_id = 1 ORDER BY id DESC LIMIT 1);
```

Ooops... now client 40 has 0 orders. But that's fine:

```
 client_id | c
-----------+---
         2 | 1
        40 | 0
         1 | 2
(3 rows)
```

When creating a trigger, it locks the table with a
`ShareRowExclusiveLock`. This lock protects a table against concurrent
data changes (DDL, insert, update, delete, etc), and is self-exclusive
so that only one session can hold it at a time.

If you open up another psql session after the first `CREATE TRIGGER`
gets run from within the transaction, and run the following command:

```sql
DELETE FROM orders_count;
```

It will block until the transaction finishes, which is when the lock will be released.

---------

Question - If we used UPSERT in favor of separate statements:

```sql
SELECT 1 AS exists FROM test_count WHERE client_id = NEW.client_id LIMIT 1 INTO row;

IF row.exists THEN
  UPDATE test_count SET c = c + 1 WHERE client_id = NEW.client_id;
ELSE
  INSERT INTO test_count(client_id, c) VALUES(NEW.client_id, 1);
END IF;
```

- Would the function be subject to race conditions? Would we have to
  use an isolated transaction?
- How would we handle atomic updates to this table with application
  code instead of PG functions and triggers? Any edge cases to be
  aware of?
